{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.ndimage import correlate, convolve\n",
    "from skimage import feature\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_waldo = plt.imread(\"waldo.png\")\n",
    "original_template = plt.imread(\"template.png\")\n",
    "\n",
    "kernel = np.array([[0, 0.5, 0],\n",
    "                [0.125, 0.5, 0.5],\n",
    "                [0, 0.125, 0.125]])\n",
    "# kernel = np.array([[0.25,1,0.25],[1,4,1],[0.25,1,0.25]])\n",
    "separable_filter = np.array([[0.25,1,0.25],[1,4,1],[0.25,1,0.25]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 (a) Naive Cross Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_cross_corr(image: np.ndarray, kernel: np.ndarray):\n",
    "    if len(image.shape) > 2:\n",
    "        image = np.dot(image[...,:3], [0.299, 0.587, 0.114])        \n",
    "\n",
    "    v_padding = kernel.shape[0]//2\n",
    "    h_padding = kernel.shape[1]//2\n",
    "    padded_image = np.pad(image, [(v_padding, v_padding),(h_padding, h_padding)], mode='constant')\n",
    "    \n",
    "    result = np.zeros([image.shape[0], image.shape[1]])\n",
    "    for i in range(v_padding, padded_image.shape[0] - v_padding):\n",
    "        for j in range(h_padding, padded_image.shape[1] - h_padding):\n",
    "            result[i-v_padding, j-h_padding] = np.sum(padded_image[i-v_padding:i+v_padding+1, j-h_padding:j+h_padding+1] * kernel)\n",
    "    return result\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "naive_cross_corr_result = naive_cross_corr(original_waldo, kernel)\n",
    "end_time = time.time()\n",
    "naive_cross_corr_time = end_time - start_time\n",
    "\n",
    "f, axarr = plt.subplots(1, 2)\n",
    "axarr[0].imshow(original_waldo)\n",
    "axarr[0].set_title(\"Original Waldo\")\n",
    "axarr[1].imshow(naive_cross_corr_result, cmap='gray')\n",
    "axarr[1].set_title(\"Waldo naive cross correlated\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 (b) Is filter separable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_separable(kernel: np.ndarray):\n",
    "    _,s,_ = np.linalg.svd(kernel)\n",
    "    return s[0] > 1e-5 and all(x <= 1e-5 for x in s[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 (c) Separable Cross-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separable_cross_corr(image: np.ndarray, kernel: np.ndarray):\n",
    "    if len(image.shape) > 2:\n",
    "        image = np.dot(image[...,:3], [0.299, 0.587, 0.114])\n",
    "    \n",
    "    if not is_separable(kernel):\n",
    "        kernel = separable_filter\n",
    "    \n",
    "    u,s,v = np.linalg.svd(kernel)\n",
    "    v_vector = (u[:,0] * np.sqrt(s[0])).reshape((u.shape[0],1))\n",
    "    h_vector = (v[0,:] * np.sqrt(s[0])).reshape((1,v.shape[1]))\n",
    "\n",
    "    cross_corr_intermediate = naive_cross_corr(image, h_vector)\n",
    "    final_cross_corr = naive_cross_corr(cross_corr_intermediate, v_vector)\n",
    "\n",
    "    return final_cross_corr\n",
    "\n",
    "start_time = time.time()\n",
    "separable_cross_corr_result = separable_cross_corr(original_waldo, kernel)\n",
    "end_time = time.time()\n",
    "separable_cross_corr_time = end_time - start_time\n",
    "\n",
    "print(f\"Naive Cross-corr time: {naive_cross_corr_time} sec\")\n",
    "print(f\"Separable Cross-corr time: {separable_cross_corr_time} sec\")\n",
    "\n",
    "f, axarr = plt.subplots(1, 2)\n",
    "axarr[0].imshow(original_waldo)\n",
    "axarr[0].set_title(\"Original Waldo\")\n",
    "axarr[1].imshow(separable_cross_corr_result, cmap='gray')\n",
    "axarr[1].set_title(\"Waldo separable cross correlated\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 (d) Separable Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separable_cross_conv(image: np.ndarray, kernel: np.ndarray):\n",
    "    if len(image.shape) > 2:\n",
    "        image = np.dot(image[...,:3], [0.299, 0.587, 0.114])\n",
    "    \n",
    "    if not is_separable(kernel):\n",
    "        kernel = separable_filter\n",
    "\n",
    "    u,s,v = np.linalg.svd(np.flip(kernel))\n",
    "    v_vector = (u[:,0] * np.sqrt(s[0])).reshape((u.shape[0],1))\n",
    "    h_vector = (v[0,:] * np.sqrt(s[0])).reshape((1,v.shape[1]))\n",
    "    cross_conv_intermediate = naive_cross_corr(image, h_vector)\n",
    "    final_cros_conv = naive_cross_corr(cross_conv_intermediate, v_vector)\n",
    "\n",
    "    return final_cros_conv\n",
    "\n",
    "separable_cross_conv_result = separable_cross_conv(original_waldo, kernel)\n",
    "\n",
    "f, axarr = plt.subplots(1, 2)\n",
    "axarr[0].imshow(original_waldo)\n",
    "axarr[0].set_title(\"Original Waldo\")\n",
    "axarr[1].imshow(separable_cross_conv_result, cmap='gray')\n",
    "axarr[1].set_title(\"Waldo separable cross convoluted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scipy_cross_corr = correlate(np.dot(original_waldo[...,:3], [0.299, 0.587, 0.114]), kernel, mode='constant')\n",
    "scipy_cross_conv = convolve(np.dot(original_waldo[...,:3], [0.299, 0.587, 0.114]), kernel, mode='constant')\n",
    "naive_cross_conv = naive_cross_corr(original_waldo, np.flip(kernel))\n",
    "\n",
    "print(f\"Scipy corr image:\\t\\n{scipy_cross_corr}\")\n",
    "print(f\"Naive corr image:\\t\\n{naive_cross_corr_result}\")\n",
    "print(f\"Separable corr image:\\t\\n{separable_cross_corr_result}\")\n",
    "\n",
    "print(f\"Scipy conv image:\\t\\n{scipy_cross_conv}\")\n",
    "print(f\"Naive conv image:\\t\\n{naive_cross_conv}\")\n",
    "print(f\"Separable conv image:\\t\\n{separable_cross_conv_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Implementation of Gaussian filter generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussian_filter(size: int, sigma: int):\n",
    "    x, y = np.meshgrid(np.arange(-size//2 + 1, size//2 + 1), np.arange(-size//2 + 1, size//2 + 1))\n",
    "    normal = 1 / (2 * np.pi * sigma**2)\n",
    "    kernel = normal * np.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
    "    return kernel\n",
    "\n",
    "new_waldo = convolve(np.dot(original_waldo[...,:3], [0.299, 0.587, 0.114]), generate_gaussian_filter(3, 2), mode='constant')\n",
    "\n",
    "f, axarr = plt.subplots(1, 2)\n",
    "axarr[0].imshow(original_waldo)\n",
    "axarr[0].set_title(\"Original Waldo\")\n",
    "axarr[1].imshow(new_waldo, cmap='gray')\n",
    "axarr[1].set_title(\"Waldo convoluted using generated filter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 (a) Gradients computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_computation(image: np.ndarray):\n",
    "    if len(image.shape) > 2:\n",
    "        image = np.dot(image[...,:3], [0.299, 0.587, 0.114])\n",
    "    \n",
    "    sobel_x = np.array([[-1, 0, 1], \n",
    "                        [-2, 0, 2], \n",
    "                        [-1, 0, 1]])\n",
    "    sobel_y = np.array([[1, 2, 1], \n",
    "                        [0, 0, 0], \n",
    "                        [-1, -2, -1]])\n",
    "\n",
    "    gradient_x = correlate(image, sobel_x, mode='constant')\n",
    "    gradient_y = correlate(image, sobel_y, mode='constant')\n",
    "\n",
    "    magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "    direction = np.arctan2(gradient_y, gradient_x)\n",
    "\n",
    "    return magnitude, direction\n",
    "\n",
    "waldo_magnitude, waldo_direction = gradient_computation(original_waldo)\n",
    "template_magnitude, template_direction = gradient_computation(original_template)\n",
    "\n",
    "f, axarr = plt.subplots(1, 2)\n",
    "axarr[0].imshow(waldo_magnitude, cmap=plt.get_cmap('gray'))\n",
    "axarr[0].set_title(\"Waldo Magnitude\")\n",
    "axarr[1].imshow(waldo_direction, cmap=plt.get_cmap('gray'))\n",
    "axarr[1].set_title(\"Waldo Direction\")\n",
    "plt.show()\n",
    "\n",
    "f, axarr = plt.subplots(1, 2)\n",
    "axarr[0].imshow(template_magnitude, cmap=plt.get_cmap('gray'))\n",
    "axarr[0].set_title(\"Template Magnitude\")\n",
    "axarr[1].imshow(template_direction, cmap=plt.get_cmap('gray'))\n",
    "axarr[1].set_title(\"Template Direction\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 (b) Localize template on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localize(image: np.ndarray, template: np.ndarray):\n",
    "    if len(image.shape) > 2:\n",
    "        image = np.dot(image[...,:3], [0.299, 0.587, 0.114])\n",
    "    if len(template.shape) > 2:\n",
    "        template = np.dot(template[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "    image_magnitude, _ = gradient_computation(image)\n",
    "    template_magnitude, _ = gradient_computation(template)\n",
    "\n",
    "    normalized_image_magitude = (image_magnitude-np.mean(image_magnitude))/(np.max(image_magnitude)-np.min(image_magnitude))\n",
    "    normalized_template_magitude = (template_magnitude-np.mean(template_magnitude))/(np.max(template_magnitude)-np.min(template_magnitude))\n",
    "    normalized_cross_corr = correlate(normalized_image_magitude, normalized_template_magitude, mode='constant')\n",
    "\n",
    "    return normalized_cross_corr\n",
    "\n",
    "\n",
    "localization = localize(original_waldo, original_template)\n",
    "\n",
    "max_point = np.argmax(localization)\n",
    "image_width = original_waldo.shape[1]\n",
    "template_height, template_width, _ = original_template.shape\n",
    "max_point_x, max_point_y = max_point // image_width, max_point % image_width\n",
    "bbox = np.array([[max_point_x - template_height // 2, max_point_y - template_width // 2],\n",
    "                 [max_point_x + template_height // 2, max_point_y - template_width // 2],\n",
    "                 [max_point_x + template_height // 2, max_point_y + template_width // 2],\n",
    "                 [max_point_x - template_height // 2, max_point_y + template_width // 2],\n",
    "                 [max_point_x - template_height // 2, max_point_y - template_width // 2]])\n",
    "\n",
    "f, axarr = plt.subplots(1, 2)\n",
    "axarr[0].imshow(original_waldo, cmap=plt.get_cmap('gray'))\n",
    "axarr[0].set_title(\"Waldo original template hilighted\")\n",
    "axarr[0].plot(bbox[:, 1], bbox[:, 0], 'r')\n",
    "\n",
    "axarr[1].imshow(localization, cmap=plt.get_cmap('gray'))\n",
    "axarr[1].set_title(\"Template Localized on Waldo\")\n",
    "axarr[1].plot(bbox[:, 1], bbox[:, 0], 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Canny edge detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detector(image: np.ndarray):\n",
    "    if len(image.shape) > 2:\n",
    "        image = np.dot(image[...,:3], [0.299, 0.587, 0.114])\n",
    "    \n",
    "    kernel = generate_gaussian_filter(3, 2)\n",
    "    correlated = correlate(image, kernel, mode='constant')\n",
    "    gradient_magnitude, gradient_direction = gradient_computation(correlated)\n",
    "\n",
    "    suppressed_magnitude = np.zeros(gradient_magnitude.shape)\n",
    "    \n",
    "    for i in range(1, gradient_magnitude.shape[0] - 1):\n",
    "        for j in range(1, gradient_magnitude.shape[1] - 1):\n",
    "            angle = abs(gradient_direction[i, j])\n",
    "\n",
    "            if (0 <= angle < np.pi / 8) or (7 * np.pi / 8 <= angle <= np.pi):\n",
    "                neighbors = [gradient_magnitude[i, j - 1], gradient_magnitude[i, j + 1]]\n",
    "            elif np.pi / 8 <= angle < 3 * np.pi / 8:\n",
    "                neighbors = [gradient_magnitude[i + 1, j - 1], gradient_magnitude[i - 1, j + 1]]\n",
    "            elif 3 * np.pi / 8 <= angle < 5 * np.pi / 8:\n",
    "                neighbors = [gradient_magnitude[i + 1, j], gradient_magnitude[i - 1, j]]\n",
    "            elif 5 * np.pi / 8 <= angle < 7 * np.pi / 8:\n",
    "                neighbors = [gradient_magnitude[i + 1, j + 1], gradient_magnitude[i - 1, j - 1]]\n",
    "\n",
    "            if gradient_magnitude[i, j] >= max(neighbors):\n",
    "                suppressed_magnitude[i, j] = gradient_magnitude[i, j]\n",
    "\n",
    "    return suppressed_magnitude\n",
    "\n",
    "canny_edges = canny_edge_detector(original_waldo)\n",
    "\n",
    "plt.imshow(canny_edges, cmap=plt.get_cmap('gray'))\n",
    "plt.title(\"Canny edge detection on waldo\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
